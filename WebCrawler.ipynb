{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adba34c6-e99b-47a9-ada2-da4038158021",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/_compression.py:15: ScrapyDeprecationWarning: You have brotlipy installed, and Scrapy will use it, but Scrapy support for brotlipy is deprecated and will stop working in a future version of Scrapy. brotlipy itself is deprecated, it has been superseded by brotlicffi (not currently supported by Scrapy). Please, uninstall brotlipy and install brotli instead. brotlipy has the same import name as brotli, so keeping both installed is strongly discouraged.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "#!pip install scrapy\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8e98f78-8175-45f8-ace5-e8143860f772",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-22 16:55:00 [scrapy.utils.log] INFO: Scrapy 2.11.2 started (bot: scrapybot)\n",
      "2024-08-22 16:55:00 [scrapy.utils.log] INFO: Versions: lxml 4.9.2.0, libxml2 2.9.13, cssselect 1.2.0, parsel 1.9.1, w3lib 2.2.1, Twisted 24.7.0, Python 3.10.8 (main, Nov 24 2022, 08:08:27) [Clang 14.0.6 ], pyOpenSSL 22.0.0 (OpenSSL 1.1.1w  11 Sep 2023), cryptography 38.0.1, Platform macOS-14.6.1-arm64-arm-64bit\n",
      "2024-08-22 16:55:00 [scrapy.addons] INFO: Enabled addons:\n",
      "[]\n",
      "2024-08-22 16:55:00 [py.warnings] WARNING: /Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/request.py:254: ScrapyDeprecationWarning: '2.6' is a deprecated value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting.\n",
      "\n",
      "It is also the default value. In other words, it is normal to get this warning if you have not defined a value for the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting. This is so for backward compatibility reasons, but it will change in a future version of Scrapy.\n",
      "\n",
      "See the documentation of the 'REQUEST_FINGERPRINTER_IMPLEMENTATION' setting for information on how to handle this deprecation.\n",
      "  return cls(crawler)\n",
      "\n",
      "2024-08-22 16:55:00 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.selectreactor.SelectReactor\n",
      "2024-08-22 16:55:00 [scrapy.extensions.telnet] INFO: Telnet Password: a52c2824ca2ec1df\n",
      "2024-08-22 16:55:00 [scrapy.middleware] INFO: Enabled extensions:\n",
      "['scrapy.extensions.corestats.CoreStats',\n",
      " 'scrapy.extensions.telnet.TelnetConsole',\n",
      " 'scrapy.extensions.memusage.MemoryUsage',\n",
      " 'scrapy.extensions.logstats.LogStats']\n",
      "2024-08-22 16:55:00 [scrapy.crawler] INFO: Overridden settings:\n",
      "{}\n",
      "2024-08-22 16:55:00 [scrapy.middleware] INFO: Enabled downloader middlewares:\n",
      "['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',\n",
      " 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',\n",
      " 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',\n",
      " 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',\n",
      " 'scrapy.downloadermiddlewares.retry.RetryMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',\n",
      " 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',\n",
      " 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',\n",
      " 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',\n",
      " 'scrapy.downloadermiddlewares.stats.DownloaderStats']\n",
      "2024-08-22 16:55:00 [scrapy.middleware] INFO: Enabled spider middlewares:\n",
      "['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',\n",
      " 'scrapy.spidermiddlewares.referer.RefererMiddleware',\n",
      " 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',\n",
      " 'scrapy.spidermiddlewares.depth.DepthMiddleware']\n",
      "2024-08-22 16:55:00 [scrapy.middleware] INFO: Enabled item pipelines:\n",
      "[]\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] INFO: Spider opened\n",
      "2024-08-22 16:55:00 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)\n",
      "2024-08-22 16:55:00 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/the_crow_2024/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/deadpool_and_wolverine/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/didi_2024/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/blink_twice/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/stream/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/it_ends_with_us/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/alien_romulus/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/the_forge/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:00 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.rottentomatoes.com//m/the_crow_2024/reviews?type=user> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/defer.py\", line 279, in iter_errback\n",
      "    yield next(it)\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/python.py\", line 350, in __next__\n",
      "    return next(self.data)\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/python.py\", line 350, in __next__\n",
      "    return next(self.data)\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py\", line 352, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result or ())\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py\", line 27, in <genexpr>\n",
      "    return (r for r in result or () if self._filter(r, spider))\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py\", line 31, in <genexpr>\n",
      "    return (r for r in result or () if self._filter(r, response, spider))\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/var/folders/1p/ywypk65n0x37lpkgnmk0zbhr0000gn/T/ipykernel_28558/599444540.py\", line 37, in parse\n",
      "    scraped_text.append(text[0].strip())\n",
      "IndexError: list index out of range\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/deadpool_and_wolverine/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/didi_2024/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/didi_2024/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/didi_2024/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/didi_2024/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/deadpool_and_wolverine/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/deadpool_and_wolverine/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/deadpool_and_wolverine/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/blink_twice/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/blink_twice/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/blink_twice/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/blink_twice/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/stream/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/stream/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/stream/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/stream/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/it_ends_with_us/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/it_ends_with_us/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/it_ends_with_us/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/it_ends_with_us/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/alien_romulus/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/alien_romulus/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/alien_romulus/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/alien_romulus/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/the_forge/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/the_forge/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/the_forge/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider must return request, item, or None, got 'set' in <GET https://www.rottentomatoes.com//m/the_forge/reviews?type=user>\n",
      "2024-08-22 16:55:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET https://www.rottentomatoes.com//m/greedy_people/reviews?type=user> (referer: None)\n",
      "2024-08-22 16:55:01 [scrapy.core.scraper] ERROR: Spider error processing <GET https://www.rottentomatoes.com//m/greedy_people/reviews?type=user> (referer: None)\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/defer.py\", line 279, in iter_errback\n",
      "    yield next(it)\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/python.py\", line 350, in __next__\n",
      "    return next(self.data)\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/utils/python.py\", line 350, in __next__\n",
      "    return next(self.data)\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/spidermiddlewares/referer.py\", line 352, in <genexpr>\n",
      "    return (self._set_referer(r, response) for r in result or ())\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/spidermiddlewares/urllength.py\", line 27, in <genexpr>\n",
      "    return (r for r in result or () if self._filter(r, spider))\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/spidermiddlewares/depth.py\", line 31, in <genexpr>\n",
      "    return (r for r in result or () if self._filter(r, response, spider))\n",
      "  File \"/Users/pibhadau/miniconda3/lib/python3.10/site-packages/scrapy/core/spidermw.py\", line 106, in process_sync\n",
      "    for r in iterable:\n",
      "  File \"/var/folders/1p/ywypk65n0x37lpkgnmk0zbhr0000gn/T/ipykernel_28558/599444540.py\", line 37, in parse\n",
      "    scraped_text.append(text[0].strip())\n",
      "IndexError: list index out of range\n",
      "2024-08-22 16:55:01 [scrapy.core.engine] INFO: Closing spider (finished)\n",
      "2024-08-22 16:55:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:\n",
      "{'downloader/request_bytes': 2343,\n",
      " 'downloader/request_count': 9,\n",
      " 'downloader/request_method_count/GET': 9,\n",
      " 'downloader/response_bytes': 254262,\n",
      " 'downloader/response_count': 9,\n",
      " 'downloader/response_status_count/200': 9,\n",
      " 'elapsed_time_seconds': 0.687209,\n",
      " 'finish_reason': 'finished',\n",
      " 'finish_time': datetime.datetime(2024, 8, 22, 23, 55, 1, 207108, tzinfo=datetime.timezone.utc),\n",
      " 'httpcompression/response_bytes': 1351205,\n",
      " 'httpcompression/response_count': 9,\n",
      " 'log_count/DEBUG': 10,\n",
      " 'log_count/ERROR': 30,\n",
      " 'log_count/INFO': 10,\n",
      " 'log_count/WARNING': 1,\n",
      " 'memusage/max': 103022592,\n",
      " 'memusage/startup': 103022592,\n",
      " 'response_received_count': 9,\n",
      " 'scheduler/dequeued': 9,\n",
      " 'scheduler/dequeued/memory': 9,\n",
      " 'scheduler/enqueued': 9,\n",
      " 'scheduler/enqueued/memory': 9,\n",
      " 'spider_exceptions/IndexError': 2,\n",
      " 'start_time': datetime.datetime(2024, 8, 22, 23, 55, 0, 519899, tzinfo=datetime.timezone.utc)}\n",
      "2024-08-22 16:55:01 [scrapy.core.engine] INFO: Spider closed (finished)\n"
     ]
    }
   ],
   "source": [
    "from scrapy.crawler import CrawlerProcess\n",
    "from scrapy.utils.project import get_project_settings\n",
    "\n",
    "scraped_text = []\n",
    "title = []\n",
    "#dic = {}\n",
    "#j =0\n",
    "\n",
    "movies_list =['/m/the_crow_2024',\n",
    " '/m/blink_twice',\n",
    " '/m/deadpool_and_wolverine',\n",
    " '/m/it_ends_with_us',\n",
    " '/m/alien_romulus',\n",
    " '/m/didi_2024',\n",
    " '/m/the_forge',\n",
    " '/m/stream',\n",
    " '/m/greedy_people']\n",
    "class MySpider(scrapy.Spider):\n",
    "    name = 'my_spider'\n",
    "    \n",
    "  \n",
    "    start_urls = [f'https://www.rottentomatoes.com/{movie}/reviews?type=user' for movie in movies_list ]  # Replace with the URL you want to scrape\n",
    "\n",
    "    def parse(self, response):\n",
    "\n",
    "        title.append(response.xpath(f'/html/body/div[3]/main/div/div/section/div/h2').get())\n",
    " \n",
    "        for i in range(1,5):\n",
    "\n",
    "          text = response.xpath(f'/html/body/div[3]/main/div/div/section/div/div[1]/div[{i}]/div[2]/drawer-more/p/text()').getall()\n",
    "          #//*[@id=\"reviews\"]/div[1]/div[2]/div[2]/drawer-more/p/text()\n",
    "                                #/html/body/div[3]/main/div/div/section/div/div[1]/div[1]/div[2]/drawer-more/p/text()\n",
    "                                #/html/body/div[3]/main/div/div/section/div/div[1]/div[2]/div[2]/drawer-more/p/text()\n",
    "          #if len(text)>0:\n",
    "          yield {\n",
    "              \n",
    "                scraped_text.append(text[0].strip())\n",
    "                \n",
    "          }\n",
    "       # scraped_text.append(\"#########\")\n",
    "        #dic[title[j+1]] = scraped_text\n",
    "\n",
    "# Configure and run the Scrapy process\n",
    "process = CrawlerProcess(get_project_settings())\n",
    "process.crawl(MySpider)\n",
    "process.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2858d414-fea3-4f70-8ea6-7310e1fb636a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great comedy. The emotional stuff didn’t work for me.',\n",
       " 'It was OK but monotonous.',\n",
       " 'Found it hard to connect with this film because the protagonist always felt so emotionless and unlikable.',\n",
       " 'It was cringey in all the best ways for a coming-of-age movie but also very nostalgic for older viewers. Seeing the growth of the main lead and his family and friends throughout the film was heartwarming and even made me tear up. Cinematography and script captured this time of life beautifully.',\n",
       " 'Very interesting look into adolescence in 2008.',\n",
       " '3D was awesome in quality, love all the deadpool movies!',\n",
       " 'Awesome... I\\'ve already seen it twice. Everything from the music to the action sequences, passing through the cameos. I\\'m sure to watch it again when it becomes available in Disney plus. The best thing that has come out of Marvel since End Game. Even the antagonist (Cassandra) when asked why she does what she does the answer is \"I wish I knew\" that line right there is brilliant. Do yourself a favor and go see it with a big bucket of popcorn.',\n",
       " 'Amazing brought back so many memories of my Childhood watching Xmen 97',\n",
       " 'The movie was too long and slow. The reveal should have happened 20 minutes sooner.',\n",
       " 'Had me on the edge of my seat. All the actresses and actors did a phenomenal job at their performances. Such a great climax and twist to the story. Zöe Kravitz did her big one directing the movie as well. 10/10 film.',\n",
       " 'It is a movie that grips you from the beginning, and one by one drops hints which begs you to think what happened earlier and what is about to happen. A really captivating movie with a good twist',\n",
       " 'Channing Tatum delivers a great performance but the movie is quite slow and the ending is quite confusing.',\n",
       " 'If your into “Horror” then STREAM is your go to for the summer movie of 2024! Incredible cast and crew that worked so hard to bring you to edge of your seat. Definitely a must see from the team that brought you Terrifier 2.',\n",
       " 'The movie was absolutely amazing! I was on the edge of my seat the entire movie! The cast was spectacular and this is a must watch!',\n",
       " 'A must see if you’re into slasher films. Perfect amount of gore! It also had a good line up.',\n",
       " 'I just went and saw stream twice in the same day it was a great movie I enjoyed every second of it can’t wait to buy it on streaming services. The kills were very creative. The cast were terrific I got no complaints ready for the sequel.',\n",
       " 'I wish I had seen Justin’s marketing and positioning of this movie first. We thought this was a rom com based on blake’s come with friends and wear florals!!!!!!!! Most of us still would have seen, but why on earth are the other cast trying to hide the topic. Unfortunately triggered one of our friends that at this time did not want to have to watch DV due to own trauma.',\n",
       " 'Acting was strong, story kind of fell apart as they were not telling the entire story…  the affair she was obviously having during the marriage, the affection she was denying her husband, etc.  it became obvious. The lesson about ending domestic abuse is a great message, but they needed to tell the entire story.',\n",
       " 'It was awesome! I cant wait for the sequel!',\n",
       " 'Creative way of showing different signs of spousal abuse.',\n",
       " 'Its like taking Alien 3, Alien Ressurection, Covernant and Prometheus, sticking them in a belnder. Eating it, and seeing what comes out at the end.  as a fan of this series for me this is close to the worst one. Visually its stunning. But everything else about it makes AVP look oscar worthy.',\n",
       " 'The last 10-15 minutes killed the reason why I wanted to see this movie. I just really want to see Aliens. But it’s just not happened much as I want',\n",
       " 'This movie suffers from the same chronic issues as its predecessors.  The same tropes in the same style done in the same order.  It also has an apparent compulsion to shoehorn some new and needlessly bizarre xenomorph variant into the story as if it were a boss fight at the end of a bad RPG.  Combine that with simplistic and flat suspense that serves as nothing but a really thin veil for the next cheap jump-scare attempt.  Cailee Spaeny actually does well in her role, and the character itself is relatively interesting, as is David Jonsson.  But other than that, the rest of the characters have nothing at all to endear them to the audience, and come off entirely as expendable from the outset.  You know exactly what\\'s about to happen, to whom, and when...the second they\\'re even introduced.  The only real horror in this movie is how slow and predictable it is.  Which is saying something since the formula for an \"Alien\" movie isn\\'t exactly complex.  And yet...they still messed it up completely.  This is only entertaining for those with the attention span of a gnat, and the memory of a goldfish.  The only other good thing...most of the effects are actually quite stunning.  There are a few flubs...but mostly the effects team are really hard-carrying this movie all on their own.',\n",
       " \"Best movie of Alien's franchise in decades!\",\n",
       " 'Wonderful story of  forgiveness, love and discipleship!!!',\n",
       " 'This was the best movie!!! I would highly recommend it to everyone! A must see!!',\n",
       " 'I thought it was a powerful movie!',\n",
       " 'The movie was very inspiring and a real touching and uplifting movie. Will go see it again.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text = [t.replace(\"\\n\", \" \") for t in scraped_text]\n",
    "clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d9a6a-10f6-4f7b-a0fa-6691ff17d26e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
